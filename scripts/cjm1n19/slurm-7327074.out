Running SLURM prolog script on pink51.cluster.local
===============================================================================
Job started on Wed Apr 23 17:19:37 BST 2025
Job ID          : 7327074
Job name        : train_glue.sh
WorkDir         : /mainfs/lyceum/cjm1n19/LoftQ/scripts/cjm1n19
Command         : /mainfs/lyceum/cjm1n19/LoftQ/scripts/cjm1n19/DeBERTaV3-base/train_glue.sh
Partition       : lyceum
Num hosts       : 1
Num cores       : 32
Num of tasks    : 1
Hosts allocated : pink51
Job Output Follows ...
===============================================================================
[2025-04-23 17:20:52,803] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Using the latest cached version of the dataset since glue couldn't be found on the Hugging Face Hub
04/23/2025 17:21:07 - WARNING - datasets.load - Using the latest cached version of the dataset since glue couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'mnli' at /scratch/cjm1n19/huggingface/datasets/glue/mnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c (last modified on Wed Apr 23 17:00:14 2025).
04/23/2025 17:21:07 - WARNING - datasets.packaged_modules.cache.cache - Found the latest cached dataset configuration 'mnli' at /scratch/cjm1n19/huggingface/datasets/glue/mnli/0.0.0/bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c (last modified on Wed Apr 23 17:00:14 2025).
/lyceum/cjm1n19/.conda/envs/comp6258_env/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:559: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.
  warnings.warn(
Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.
Namespace(task_name='mnli', train_file=None, validation_file=None, max_length=128, pad_to_max_length=False, model_name_or_path='microsoft/deberta-v3-base', use_slow_tokenizer=False, per_device_train_batch_size=32, per_device_eval_batch_size=64, learning_rate=0.0001, weight_decay=0.0, num_train_epochs=5, max_train_steps=None, gradient_accumulation_steps=1, lr_scheduler_type=<SchedulerType.LINEAR: 'linear'>, num_warmup_steps=0, output_dir='output', seed=None, push_to_hub=False, use_fp16=False, hub_model_id=None, hub_token=None, checkpointing_steps=None, resume_from_checkpoint=None, with_tracking=False, report_to='all', ignore_mismatched_sizes=False, reduced_rank=32.0, int_bit=4, decompose=True, qlora=False, loftq=True, decomposed_pretrained_ckpt_path=None, quant_embedding=True, quant_method='uniform', num_iter=5, eval=False)
====================================================
word_embeddings Embedding(128100, 768, padding_idx=0)
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
low rank adapter with rank 32 using LoftQ
====================================================
rel_embeddings Embedding(512, 768)
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
low rank adapter with rank 32 using LoftQ
====================================================
key_proj 768
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
low rank adapter with rank 32 using LoftQ
====================================================
query_proj 768
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
low rank adapter with rank 32 using LoftQ
====================================================
value_proj 768
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
low rank adapter with rank 32 using LoftQ
====================================================
dense 768
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
low rank adapter with rank 32 using LoftQ
====================================================
dense 3072
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
low rank adapter with rank 32 using LoftQ
====================================================
dense 768
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
low rank adapter with rank 32 using LoftQ
====================================================
key_proj 768
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
low rank adapter with rank 32 using LoftQ
====================================================
query_proj 768
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
low rank adapter with rank 32 using LoftQ
====================================================
value_proj 768
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
low rank adapter with rank 32 using LoftQ
====================================================
dense 768
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
low rank adapter with rank 32 using LoftQ
====================================================
dense 3072
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
low rank adapter with rank 32 using LoftQ
====================================================
dense 768
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
low rank adapter with rank 32 using LoftQ
====================================================
key_proj 768
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
low rank adapter with rank 32 using LoftQ
====================================================
query_proj 768
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
low rank adapter with rank 32 using LoftQ
====================================================
value_proj 768
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
low rank adapter with rank 32 using LoftQ
====================================================
dense 768
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
low rank adapter with rank 32 using LoftQ
====================================================
dense 3072
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
low rank adapter with rank 32 using LoftQ
====================================================
dense 768
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
low rank adapter with rank 32 using LoftQ
====================================================
key_proj 768
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
low rank adapter with rank 32 using LoftQ
====================================================
query_proj 768
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
low rank adapter with rank 32 using LoftQ
====================================================
value_proj 768
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
low rank adapter with rank 32 using LoftQ
====================================================
dense 768
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
low rank adapter with rank 32 using LoftQ
====================================================
dense 3072
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
low rank adapter with rank 32 using LoftQ
====================================================
dense 768
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
low rank adapter with rank 32 using LoftQ
====================================================
key_proj 768
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
low rank adapter with rank 32 using LoftQ
====================================================
query_proj 768
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
low rank adapter with rank 32 using LoftQ
====================================================
value_proj 768
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
low rank adapter with rank 32 using LoftQ
====================================================
dense 768
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
low rank adapter with rank 32 using LoftQ
====================================================
dense 3072
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
low rank adapter with rank 32 using LoftQ
====================================================
dense 768
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
low rank adapter with rank 32 using LoftQ
====================================================
key_proj 768
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
low rank adapter with rank 32 using LoftQ
====================================================
query_proj 768
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
low rank adapter with rank 32 using LoftQ
====================================================
value_proj 768
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
low rank adapter with rank 32 using LoftQ
====================================================
dense 768
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
low rank adapter with rank 32 using LoftQ
====================================================
dense 3072
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
low rank adapter with rank 32 using LoftQ
====================================================
dense 768
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
low rank adapter with rank 32 using LoftQ
====================================================
key_proj 768
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
low rank adapter with rank 32 using LoftQ
====================================================
query_proj 768
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
low rank adapter with rank 32 using LoftQ
====================================================
value_proj 768
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
low rank adapter with rank 32 using LoftQ
====================================================
dense 768
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
low rank adapter with rank 32 using LoftQ
====================================================
dense 3072
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
low rank adapter with rank 32 using LoftQ
====================================================
dense 768
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
low rank adapter with rank 32 using LoftQ
====================================================
key_proj 768
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
low rank adapter with rank 32 using LoftQ
====================================================
query_proj 768
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
low rank adapter with rank 32 using LoftQ
====================================================
value_proj 768
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
low rank adapter with rank 32 using LoftQ
====================================================
dense 768
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
low rank adapter with rank 32 using LoftQ
====================================================
dense 3072
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
low rank adapter with rank 32 using LoftQ
====================================================
dense 768
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
low rank adapter with rank 32 using LoftQ
====================================================
key_proj 768
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
low rank adapter with rank 32 using LoftQ
====================================================
query_proj 768
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
low rank adapter with rank 32 using LoftQ
====================================================
value_proj 768
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
low rank adapter with rank 32 using LoftQ
====================================================
dense 768
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
low rank adapter with rank 32 using LoftQ
====================================================
dense 3072
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
low rank adapter with rank 32 using LoftQ
====================================================
dense 768
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
low rank adapter with rank 32 using LoftQ
====================================================
key_proj 768
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
low rank adapter with rank 32 using LoftQ
====================================================
query_proj 768
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
low rank adapter with rank 32 using LoftQ
====================================================
value_proj 768
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
low rank adapter with rank 32 using LoftQ
====================================================
dense 768
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
low rank adapter with rank 32 using LoftQ
====================================================
dense 3072
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
low rank adapter with rank 32 using LoftQ
====================================================
dense 768
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
low rank adapter with rank 32 using LoftQ
====================================================
key_proj 768
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
low rank adapter with rank 32 using LoftQ
====================================================
query_proj 768
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
low rank adapter with rank 32 using LoftQ
====================================================
value_proj 768
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
low rank adapter with rank 32 using LoftQ
====================================================
dense 768
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
low rank adapter with rank 32 using LoftQ
====================================================
dense 3072
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
low rank adapter with rank 32 using LoftQ
====================================================
dense 768
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
low rank adapter with rank 32 using LoftQ
====================================================
key_proj 768
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
low rank adapter with rank 32 using LoftQ
====================================================
query_proj 768
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
low rank adapter with rank 32 using LoftQ
====================================================
value_proj 768
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
low rank adapter with rank 32 using LoftQ
====================================================
dense 768
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
low rank adapter with rank 32 using LoftQ
====================================================
dense 3072
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
low rank adapter with rank 32 using LoftQ
====================================================
dense 768
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
uniform quant with 4bits
low rank adapter with rank 32 using LoftQ
embeddings.word_embeddings.weight Parameter containing:
tensor([[-0.0142, -0.0142,  0.0182,  ..., -0.0142, -0.0142, -0.0142],
        [-0.0142, -0.1114,  0.0506,  ...,  0.0182, -0.0466,  0.0506],
        [-0.0142, -0.0466,  0.0506,  ...,  0.0182, -0.0466,  0.0506],
        ...,
        [-0.0142, -0.0142,  0.0182,  ..., -0.0142, -0.0142, -0.0142],
        [-0.0142, -0.0142,  0.0182,  ..., -0.0142, -0.0142, -0.0142],
        [-0.0142, -0.0142,  0.0182,  ..., -0.0142, -0.0142, -0.0142]],
       device='cuda:0')
embeddings.word_embeddings.weight torch.Size([128100, 768]) False
embeddings.word_embeddings.left torch.Size([128100, 32]) True
embeddings.word_embeddings.right torch.Size([32, 768]) True
embeddings.LayerNorm.weight torch.Size([768]) False
embeddings.LayerNorm.bias torch.Size([768]) False
encoder.layer.0.attention.self.query_proj.bias torch.Size([768]) False
encoder.layer.0.attention.self.query_proj.quant.weight Parameter containing:
tensor([[-0.1042,  0.0811,  0.0811,  ...,  0.0348,  0.1043,  0.0348],
        [-0.0810, -0.0116,  0.0116,  ...,  0.0579,  0.0811, -0.1042],
        [ 0.0579,  0.0116,  0.1043,  ..., -0.0116,  0.0116,  0.0116],
        ...,
        [-0.0579, -0.0116,  0.0348,  ...,  0.0116,  0.0116,  0.0348],
        [ 0.0579,  0.0811,  0.0348,  ...,  0.0811,  0.0811,  0.0579],
        [-0.1274, -0.0347,  0.0116,  ..., -0.1042,  0.0811, -0.0116]],
       device='cuda:0')
encoder.layer.0.attention.self.query_proj.quant.weight torch.Size([768, 768]) False
encoder.layer.0.attention.self.query_proj.right.weight torch.Size([32, 768]) True
encoder.layer.0.attention.self.query_proj.left.weight torch.Size([768, 32]) True
encoder.layer.0.attention.self.key_proj.bias torch.Size([768]) False
encoder.layer.0.attention.self.key_proj.quant.weight Parameter containing:
tensor([[-0.0344,  0.0116,  0.1035,  ...,  0.0346,  0.0805, -0.1722],
        [-0.0803, -0.1033, -0.0344,  ..., -0.0573,  0.1495, -0.1263],
        [-0.0344,  0.0346, -0.0114,  ..., -0.0803, -0.1263, -0.0573],
        ...,
        [-0.0344,  0.0346, -0.0803,  ...,  0.0116,  0.1035,  0.0116],
        [ 0.0346,  0.0805, -0.0803,  ...,  0.0116,  0.0576,  0.0116],
        [ 0.0116, -0.0573,  0.0576,  ..., -0.0344, -0.0114,  0.0116]],
       device='cuda:0')
encoder.layer.0.attention.self.key_proj.quant.weight torch.Size([768, 768]) False
encoder.layer.0.attention.self.key_proj.right.weight torch.Size([32, 768]) True
encoder.layer.0.attention.self.key_proj.left.weight torch.Size([768, 32]) True
encoder.layer.0.attention.self.value_proj.bias torch.Size([768]) False
encoder.layer.0.attention.self.value_proj.quant.weight Parameter containing:
tensor([[-0.0613, -0.0204,  0.0041,  ..., -0.0531,  0.0041, -0.0286],
        [-0.0041,  0.0122, -0.0041,  ..., -0.0204,  0.0204,  0.0122],
        [-0.0368, -0.0204, -0.0204,  ..., -0.0286, -0.0531, -0.0041],
        ...,
        [-0.0450,  0.0041, -0.0531,  ..., -0.0123,  0.0449,  0.0613],
        [-0.0204,  0.0449, -0.0123,  ...,  0.0041,  0.0531, -0.0531],
        [ 0.0204,  0.0204,  0.0122,  ..., -0.0368, -0.0531,  0.0286]],
       device='cuda:0')
encoder.layer.0.attention.self.value_proj.quant.weight torch.Size([768, 768]) False
encoder.layer.0.attention.self.value_proj.right.weight torch.Size([32, 768]) True
encoder.layer.0.attention.self.value_proj.left.weight torch.Size([768, 32]) True
encoder.layer.0.attention.output.dense.bias torch.Size([768]) False
encoder.layer.0.attention.output.dense.quant.weight Parameter containing:
tensor([[ 0.0449, -0.0204, -0.0204,  ...,  0.0531, -0.0368, -0.0531],
        [-0.0612,  0.0122,  0.0286,  ...,  0.0367,  0.0041, -0.0041],
        [ 0.0122,  0.0041,  0.0122,  ...,  0.0041, -0.0449, -0.0041],
        ...,
        [ 0.0286, -0.0041,  0.0612,  ...,  0.0204,  0.0122, -0.0612],
        [-0.0041,  0.0612, -0.0041,  ...,  0.0204,  0.0041, -0.0286],
        [-0.0204, -0.0123, -0.0123,  ...,  0.0531,  0.0612, -0.0286]],
       device='cuda:0')
encoder.layer.0.attention.output.dense.quant.weight torch.Size([768, 768]) False
encoder.layer.0.attention.output.dense.right.weight torch.Size([32, 768]) True
encoder.layer.0.attention.output.dense.left.weight torch.Size([768, 32]) True
encoder.layer.0.attention.output.LayerNorm.weight torch.Size([768]) False
encoder.layer.0.attention.output.LayerNorm.bias torch.Size([768]) False
encoder.layer.0.intermediate.dense.bias torch.Size([3072]) False
encoder.layer.0.intermediate.dense.quant.weight Parameter containing:
tensor([[-0.0238,  0.0047, -0.0095,  ..., -0.0238, -0.0095, -0.0095],
        [ 0.0189,  0.0474,  0.1186,  ..., -0.0238,  0.0189,  0.0332],
        [ 0.0189, -0.0238,  0.0616,  ..., -0.0238,  0.0332, -0.0238],
        ...,
        [ 0.0616, -0.0665,  0.0189,  ..., -0.0522, -0.0095,  0.0616],
        [ 0.0474, -0.0238, -0.0522,  ...,  0.0047,  0.0189, -0.0238],
        [-0.0522, -0.0522,  0.0189,  ..., -0.0095,  0.0332,  0.1186]],
       device='cuda:0')
encoder.layer.0.intermediate.dense.quant.weight torch.Size([3072, 768]) False
encoder.layer.0.intermediate.dense.right.weight torch.Size([32, 768]) True
encoder.layer.0.intermediate.dense.left.weight torch.Size([3072, 32]) True
encoder.layer.0.output.dense.bias torch.Size([768]) False
encoder.layer.0.output.dense.quant.weight Parameter containing:
tensor([[ 0.0491, -0.0492,  0.0632,  ...,  0.0491, -0.0913,  0.0070],
        [ 0.0210,  0.0070, -0.0070,  ..., -0.0913,  0.0210, -0.0070],
        [ 0.0351,  0.0210,  0.0070,  ..., -0.0632,  0.0491,  0.0210],
        ...,
        [-0.0070, -0.0211, -0.0211,  ...,  0.0210, -0.0492,  0.0351],
        [ 0.0351,  0.0351, -0.0211,  ..., -0.0070, -0.0211, -0.0492],
        [-0.0070,  0.0351,  0.0351,  ...,  0.1053, -0.0070,  0.0351]],
       device='cuda:0')
encoder.layer.0.output.dense.quant.weight torch.Size([768, 3072]) False
encoder.layer.0.output.dense.right.weight torch.Size([32, 3072]) True
encoder.layer.0.output.dense.left.weight torch.Size([768, 32]) True
encoder.layer.0.output.LayerNorm.weight torch.Size([768]) False
encoder.layer.0.output.LayerNorm.bias torch.Size([768]) False
encoder.layer.1.attention.self.query_proj.bias torch.Size([768]) False
encoder.layer.1.attention.self.query_proj.quant.weight Parameter containing:
tensor([[ 0.1425, -0.0287, -0.0477,  ...,  0.1044, -0.0477, -0.0287],
        [-0.1048,  0.0474,  0.1044,  ..., -0.0097, -0.0668, -0.0477],
        [ 0.0854, -0.0668, -0.0668,  ...,  0.0283,  0.1425, -0.0097],
        ...,
        [-0.0668, -0.0097,  0.1044,  ...,  0.0283, -0.0097, -0.0287],
        [ 0.0664, -0.0097,  0.0093,  ...,  0.0474, -0.0287, -0.1048],
        [-0.0097,  0.0474, -0.0287,  ...,  0.0474,  0.0093, -0.0287]],
       device='cuda:0')
encoder.layer.1.attention.self.query_proj.quant.weight torch.Size([768, 768]) False
encoder.layer.1.attention.self.query_proj.right.weight torch.Size([32, 768]) True
encoder.layer.1.attention.self.query_proj.left.weight torch.Size([768, 32]) True
encoder.layer.1.attention.self.key_proj.bias torch.Size([768]) False
encoder.layer.1.attention.self.key_proj.quant.weight Parameter containing:
tensor([[-0.1415,  0.0283,  0.0283,  ...,  0.0660,  0.0094,  0.0660],
        [-0.0095, -0.0660,  0.0283,  ...,  0.1037, -0.0095,  0.0283],
        [ 0.0094, -0.0660,  0.0848,  ..., -0.0095,  0.0094, -0.1226],
        ...,
        [ 0.0848, -0.0283, -0.0283,  ..., -0.0095, -0.0472, -0.1037],
        [ 0.0471, -0.0095, -0.0660,  ...,  0.0660,  0.1225,  0.0283],
        [ 0.0094, -0.0095,  0.0094,  ...,  0.0471,  0.0283, -0.0283]],
       device='cuda:0')
encoder.layer.1.attention.self.key_proj.quant.weight torch.Size([768, 768]) False
encoder.layer.1.attention.self.key_proj.right.weight torch.Size([32, 768]) True
encoder.layer.1.attention.self.key_proj.left.weight torch.Size([768, 32]) True
encoder.layer.1.attention.self.value_proj.bias torch.Size([768]) False
encoder.layer.1.attention.self.value_proj.quant.weight Parameter containing:
tensor([[-0.0613,  0.0237, -0.0330,  ...,  0.0425,  0.0520,  0.0048],
        [-0.0235,  0.0142,  0.0142,  ...,  0.0331, -0.0330,  0.0142],
        [ 0.0142, -0.0141,  0.0142,  ..., -0.0330,  0.0048,  0.0142],
        ...,
        [-0.0141,  0.0614,  0.0048,  ...,  0.0237, -0.0707,  0.0048],
        [ 0.0048, -0.0235,  0.0048,  ..., -0.0141,  0.0425, -0.0046],
        [ 0.0425,  0.0142, -0.0330,  ...,  0.0048,  0.0425,  0.0048]],
       device='cuda:0')
encoder.layer.1.attention.self.value_proj.quant.weight torch.Size([768, 768]) False
encoder.layer.1.attention.self.value_proj.right.weight torch.Size([32, 768]) True
encoder.layer.1.attention.self.value_proj.left.weight torch.Size([768, 32]) True
encoder.layer.1.attention.output.dense.bias torch.Size([768]) False
encoder.layer.1.attention.output.dense.quant.weight Parameter containing:
tensor([[-0.0048, -0.0048,  0.0048,  ..., -0.0048,  0.0240, -0.0240],
        [ 0.0336,  0.0336, -0.0336,  ..., -0.0240,  0.0336, -0.0528],
        [-0.0432,  0.0048, -0.0240,  ..., -0.0336, -0.0624,  0.0336],
        ...,
        [-0.0624,  0.0144,  0.0144,  ...,  0.0336, -0.0048,  0.0144],
        [-0.0528, -0.0432, -0.0144,  ..., -0.0336,  0.0144,  0.0527],
        [-0.0432, -0.0240,  0.0432,  ..., -0.0432, -0.0720,  0.0432]],
       device='cuda:0')
encoder.layer.1.attention.output.dense.quant.weight torch.Size([768, 768]) False
encoder.layer.1.attention.output.dense.right.weight torch.Size([32, 768]) True
encoder.layer.1.attention.output.dense.left.weight torch.Size([768, 32]) True
encoder.layer.1.attention.output.LayerNorm.weight torch.Size([768]) False
encoder.layer.1.attention.output.LayerNorm.bias torch.Size([768]) False
encoder.layer.1.intermediate.dense.bias torch.Size([3072]) False
encoder.layer.1.intermediate.dense.quant.weight Parameter containing:
tensor([[-0.0677,  0.0453,  0.0311,  ..., -0.0818,  0.0029,  0.0029],
        [ 0.0735,  0.0594,  0.0170,  ...,  0.0029, -0.0536,  0.0594],
        [ 0.0311,  0.0170, -0.0112,  ...,  0.0029, -0.0253,  0.1159],
        ...,
        [-0.0536, -0.0536,  0.0453,  ..., -0.0112, -0.0818,  0.0876],
        [ 0.0453, -0.0394, -0.0112,  ...,  0.0029,  0.0311,  0.0170],
        [ 0.0170,  0.0453,  0.0453,  ..., -0.0677,  0.0594,  0.0453]],
       device='cuda:0')
encoder.layer.1.intermediate.dense.quant.weight torch.Size([3072, 768]) False
encoder.layer.1.intermediate.dense.right.weight torch.Size([32, 768]) True
encoder.layer.1.intermediate.dense.left.weight torch.Size([3072, 32]) True
encoder.layer.1.output.dense.bias torch.Size([768]) False
encoder.layer.1.output.dense.quant.weight Parameter containing:
tensor([[-0.0329, -0.0066,  0.0986,  ..., -0.0197, -0.0066,  0.0197],
        [ 0.0329,  0.0066,  0.0986,  ...,  0.0591, -0.0197, -0.0592],
        [ 0.0591,  0.0066, -0.0986,  ..., -0.0329,  0.0066, -0.0197],
        ...,
        [-0.0460,  0.0460,  0.0197,  ..., -0.0329,  0.0723, -0.0592],
        [ 0.0066,  0.0066, -0.0329,  ...,  0.0986,  0.0066,  0.0854],
        [-0.0066, -0.0197,  0.0066,  ...,  0.0460, -0.0329,  0.0723]],
       device='cuda:0')
encoder.layer.1.output.dense.quant.weight torch.Size([768, 3072]) False
encoder.layer.1.output.dense.right.weight torch.Size([32, 3072]) True
encoder.layer.1.output.dense.left.weight torch.Size([768, 32]) True
encoder.layer.1.output.LayerNorm.weight torch.Size([768]) False
encoder.layer.1.output.LayerNorm.bias torch.Size([768]) False
encoder.layer.2.attention.self.query_proj.bias torch.Size([768]) False
encoder.layer.2.attention.self.query_proj.quant.weight Parameter containing:
tensor([[ 0.0099, -0.0493,  0.0296,  ...,  0.0888,  0.0099,  0.0494],
        [ 0.0888,  0.1480,  0.0494,  ...,  0.1283, -0.0098,  0.1480],
        [ 0.0296,  0.0888,  0.0099,  ...,  0.1480,  0.0099,  0.1283],
        ...,
        [-0.0493, -0.1085, -0.0098,  ...,  0.0691,  0.0099, -0.1479],
        [-0.1479, -0.0887, -0.0887,  ...,  0.0296,  0.0099,  0.0691],
        [-0.0098, -0.0098,  0.0099,  ...,  0.0296, -0.1282, -0.1479]],
       device='cuda:0')
encoder.layer.2.attention.self.query_proj.quant.weight torch.Size([768, 768]) False
encoder.layer.2.attention.self.query_proj.right.weight torch.Size([32, 768]) True
encoder.layer.2.attention.self.query_proj.left.weight torch.Size([768, 32]) True
encoder.layer.2.attention.self.key_proj.bias torch.Size([768]) False
encoder.layer.2.attention.self.key_proj.quant.weight Parameter containing:
tensor([[ 0.0096,  0.1075,  0.0879,  ..., -0.0099,  0.0096, -0.0295],
        [ 0.1466,  0.1270,  0.0096,  ...,  0.0488,  0.0683, -0.0490],
        [-0.1469, -0.0099,  0.0292,  ...,  0.0292,  0.0879, -0.0099],
        ...,
        [ 0.0683,  0.0879,  0.0096,  ..., -0.0490, -0.0686,  0.0096],
        [ 0.0879,  0.0879, -0.0295,  ...,  0.1270,  0.1270, -0.0686],
        [ 0.0292,  0.0292, -0.0099,  ...,  0.0879,  0.1466, -0.0099]],
       device='cuda:0')
encoder.layer.2.attention.self.key_proj.quant.weight torch.Size([768, 768]) False
encoder.layer.2.attention.self.key_proj.right.weight torch.Size([32, 768]) True
encoder.layer.2.attention.self.key_proj.left.weight torch.Size([768, 32]) True
encoder.layer.2.attention.self.value_proj.bias torch.Size([768]) False
encoder.layer.2.attention.self.value_proj.quant.weight Parameter containing:
tensor([[-0.0165, -0.0384,  0.0602,  ..., -0.0384, -0.0056,  0.0164],
        [-0.0275,  0.0492,  0.0054,  ..., -0.0165,  0.0821, -0.0275],
        [-0.0056,  0.0602,  0.0602,  ..., -0.0275, -0.0384,  0.0492],
        ...,
        [-0.0165,  0.0383,  0.0054,  ...,  0.0164, -0.0056, -0.0165],
        [ 0.0164,  0.0164, -0.0275,  ..., -0.0165, -0.0165, -0.0823],
        [ 0.0492,  0.0273, -0.0056,  ...,  0.0164, -0.0165,  0.0492]],
       device='cuda:0')
encoder.layer.2.attention.self.value_proj.quant.weight torch.Size([768, 768]) False
encoder.layer.2.attention.self.value_proj.right.weight torch.Size([32, 768]) True
encoder.layer.2.attention.self.value_proj.left.weight torch.Size([768, 32]) True
encoder.layer.2.attention.output.dense.bias torch.Size([768]) False
encoder.layer.2.attention.output.dense.quant.weight Parameter containing:
tensor([[-0.0278, -0.0056,  0.0612,  ..., -0.0612, -0.0390,  0.0167],
        [ 0.0056, -0.0390, -0.0056,  ...,  0.0056,  0.0278, -0.0723],
        [-0.0835,  0.0612, -0.0167,  ...,  0.0056, -0.0167, -0.0612],
        ...,
        [ 0.0056,  0.0834,  0.0278,  ..., -0.0167, -0.0056, -0.0167],
        [ 0.0167,  0.0501,  0.0278,  ...,  0.0056,  0.0389,  0.0389],
        [-0.0056, -0.0835,  0.0056,  ..., -0.0167, -0.0612,  0.0056]],
       device='cuda:0')
encoder.layer.2.attention.output.dense.quant.weight torch.Size([768, 768]) False
encoder.layer.2.attention.output.dense.right.weight torch.Size([32, 768]) True
encoder.layer.2.attention.output.dense.left.weight torch.Size([768, 32]) True
encoder.layer.2.attention.output.LayerNorm.weight torch.Size([768]) False
encoder.layer.2.attention.output.LayerNorm.bias torch.Size([768]) False
encoder.layer.2.intermediate.dense.bias torch.Size([3072]) False
encoder.layer.2.intermediate.dense.quant.weight Parameter containing:
tensor([[-0.0621,  0.0111, -0.0621,  ..., -0.0182,  0.0258, -0.0767],
        [ 0.0697, -0.0182, -0.0767,  ...,  0.0551,  0.0990,  0.0258],
        [-0.0328, -0.0621, -0.0035,  ..., -0.0328, -0.0621,  0.0990],
        ...,
        [-0.0328,  0.0111, -0.0621,  ..., -0.0475, -0.0621, -0.0621],
        [ 0.0551,  0.0551, -0.1060,  ..., -0.0475, -0.1207, -0.0328],
        [-0.0035, -0.0035,  0.0111,  ...,  0.0404,  0.0404, -0.0182]],
       device='cuda:0')
encoder.layer.2.intermediate.dense.quant.weight torch.Size([3072, 768]) False
encoder.layer.2.intermediate.dense.right.weight torch.Size([32, 768]) True
encoder.layer.2.intermediate.dense.left.weight torch.Size([3072, 32]) True
encoder.layer.2.output.dense.bias torch.Size([768]) False
encoder.layer.2.output.dense.quant.weight Parameter containing:
tensor([[-0.0343,  0.0343,  0.0206,  ..., -0.0069, -0.0618,  0.0618],
        [ 0.1029,  0.0343, -0.0206,  ...,  0.0480,  0.0480, -0.0892],
        [ 0.0343,  0.1029, -0.0069,  ...,  0.0206,  0.0480, -0.1030],
        ...,
        [ 0.0069,  0.1029, -0.0069,  ..., -0.0069,  0.0069, -0.0343],
        [-0.0069,  0.0755, -0.0206,  ...,  0.0206, -0.1030, -0.0755],
        [-0.0755,  0.0892,  0.0892,  ...,  0.0069,  0.0069, -0.0343]],
       device='cuda:0')
encoder.layer.2.output.dense.quant.weight torch.Size([768, 3072]) False
encoder.layer.2.output.dense.right.weight torch.Size([32, 3072]) True
encoder.layer.2.output.dense.left.weight torch.Size([768, 32]) True
encoder.layer.2.output.LayerNorm.weight torch.Size([768]) False
encoder.layer.2.output.LayerNorm.bias torch.Size([768]) False
encoder.layer.3.attention.self.query_proj.bias torch.Size([768]) False
encoder.layer.3.attention.self.query_proj.quant.weight Parameter containing:
tensor([[ 0.0880,  0.0102,  0.0102,  ...,  0.0880,  0.0297,  0.1075],
        [-0.0482, -0.0482, -0.0676,  ...,  0.0102,  0.0297,  0.0491],
        [-0.1066,  0.0491, -0.0676,  ..., -0.0093,  0.0686,  0.0491],
        ...,
        [-0.1260,  0.0880,  0.1270,  ...,  0.0686, -0.1260,  0.0491],
        [ 0.0686,  0.0491, -0.0287,  ...,  0.0102,  0.0297, -0.1066],
        [ 0.0102,  0.1464,  0.1270,  ...,  0.0880,  0.0102, -0.0287]],
       device='cuda:0')
encoder.layer.3.attention.self.query_proj.quant.weight torch.Size([768, 768]) False
encoder.layer.3.attention.self.query_proj.right.weight torch.Size([32, 768]) True
encoder.layer.3.attention.self.query_proj.left.weight torch.Size([768, 32]) True
encoder.layer.3.attention.self.key_proj.bias torch.Size([768]) False
encoder.layer.3.attention.self.key_proj.quant.weight Parameter containing:
tensor([[ 0.0867, -0.1442, -0.0095,  ..., -0.1057, -0.1442,  0.0290],
        [ 0.0482, -0.0288,  0.0867,  ..., -0.0480,  0.0290,  0.0097],
        [ 0.0674,  0.0097,  0.0097,  ..., -0.0288, -0.0095, -0.0288],
        ...,
        [-0.0865, -0.0480,  0.1059,  ...,  0.1059, -0.1250,  0.0674],
        [-0.1057,  0.0290, -0.0673,  ..., -0.0865, -0.0095, -0.1250],
        [-0.0095,  0.1444,  0.1444,  ...,  0.0482,  0.0867,  0.0097]],
       device='cuda:0')
encoder.layer.3.attention.self.key_proj.quant.weight torch.Size([768, 768]) False
encoder.layer.3.attention.self.key_proj.right.weight torch.Size([32, 768]) True
encoder.layer.3.attention.self.key_proj.left.weight torch.Size([768, 32]) True
encoder.layer.3.attention.self.value_proj.bias torch.Size([768]) False
encoder.layer.3.attention.self.value_proj.quant.weight Parameter containing:
tensor([[ 0.0670,  0.0427, -0.0427,  ...,  0.0305,  0.0427,  0.0183],
        [ 0.0061, -0.0061,  0.0427,  ..., -0.0549, -0.0427,  0.0305],
        [-0.0793,  0.0061,  0.0549,  ...,  0.0061,  0.0305, -0.0549],
        ...,
        [ 0.0183,  0.0183,  0.0061,  ..., -0.0427,  0.0427,  0.0305],
        [ 0.0549,  0.0061,  0.0305,  ..., -0.0671, -0.0427, -0.0305],
        [-0.0183, -0.0061,  0.0305,  ...,  0.0427,  0.0427, -0.0305]],
       device='cuda:0')
encoder.layer.3.attention.self.value_proj.quant.weight torch.Size([768, 768]) False
encoder.layer.3.attention.self.value_proj.right.weight torch.Size([32, 768]) True
encoder.layer.3.attention.self.value_proj.left.weight torch.Size([768, 32]) True
encoder.layer.3.attention.output.dense.bias torch.Size([768]) False
encoder.layer.3.attention.output.dense.quant.weight Parameter containing:
tensor([[-0.0308, -0.0308, -0.0678,  ...,  0.0554,  0.0677, -0.0432],
        [-0.0924, -0.0185,  0.0431,  ...,  0.0307,  0.0184, -0.0432],
        [-0.0678, -0.0432, -0.0555,  ...,  0.0677, -0.0185, -0.0185],
        ...,
        [-0.0062, -0.0924,  0.0677,  ..., -0.0185, -0.0308,  0.0307],
        [-0.0185, -0.0678,  0.0184,  ...,  0.0061, -0.0062,  0.0431],
        [ 0.0554,  0.0307, -0.0678,  ...,  0.0061, -0.0062,  0.0184]],
       device='cuda:0')
encoder.layer.3.attention.output.dense.quant.weight torch.Size([768, 768]) False
encoder.layer.3.attention.output.dense.right.weight torch.Size([32, 768]) True
encoder.layer.3.attention.output.dense.left.weight torch.Size([768, 32]) True
encoder.layer.3.attention.output.LayerNorm.weight torch.Size([768]) False
encoder.layer.3.attention.output.LayerNorm.bias torch.Size([768]) False
encoder.layer.3.intermediate.dense.bias torch.Size([3072]) False
encoder.layer.3.intermediate.dense.quant.weight Parameter containing:
tensor([[ 0.0974,  0.0094, -0.0053,  ..., -0.0053, -0.1227,  0.0094],
        [-0.0640, -0.0787, -0.0200,  ..., -0.0787, -0.0787, -0.0347],
        [ 0.0094, -0.0934, -0.1227,  ..., -0.0200,  0.0387,  0.0828],
        ...,
        [ 0.0240,  0.0534, -0.0347,  ..., -0.0053,  0.0240,  0.0240],
        [ 0.0094,  0.0240, -0.0347,  ..., -0.0347, -0.0053,  0.0534],
        [ 0.0387,  0.0681, -0.1227,  ...,  0.0094,  0.0094, -0.0347]],
       device='cuda:0')
encoder.layer.3.intermediate.dense.quant.weight torch.Size([3072, 768]) False
encoder.layer.3.intermediate.dense.right.weight torch.Size([32, 768]) True
encoder.layer.3.intermediate.dense.left.weight torch.Size([3072, 32]) True
encoder.layer.3.output.dense.bias torch.Size([768]) False
encoder.layer.3.output.dense.quant.weight Parameter containing:
tensor([[ 0.0347, -0.0069,  0.0485,  ..., -0.0069,  0.0347,  0.0208],
        [ 0.0624, -0.0346,  0.0485,  ...,  0.0624,  0.0208,  0.0208],
        [-0.0762,  0.0069, -0.0485,  ...,  0.0763,  0.0208,  0.1040],
        ...,
        [ 0.0485,  0.0485, -0.0069,  ...,  0.0069,  0.0208,  0.0208],
        [-0.1040, -0.0208, -0.0208,  ..., -0.0624,  0.0069, -0.1040],
        [-0.0485, -0.0208, -0.0485,  ...,  0.0208, -0.0208, -0.0346]],
       device='cuda:0')
encoder.layer.3.output.dense.quant.weight torch.Size([768, 3072]) False
encoder.layer.3.output.dense.right.weight torch.Size([32, 3072]) True
encoder.layer.3.output.dense.left.weight torch.Size([768, 32]) True
encoder.layer.3.output.LayerNorm.weight torch.Size([768]) False
encoder.layer.3.output.LayerNorm.bias torch.Size([768]) False
encoder.layer.4.attention.self.query_proj.bias torch.Size([768]) False
encoder.layer.4.attention.self.query_proj.quant.weight Parameter containing:
tensor([[ 0.0663,  0.0095, -0.0283,  ...,  0.0095,  0.0095, -0.0473],
        [-0.0094, -0.0094, -0.0094,  ...,  0.0852,  0.0284,  0.1041],
        [ 0.1041,  0.0852, -0.0473,  ...,  0.0095, -0.0094, -0.0283],
        ...,
        [-0.0283, -0.0283,  0.0095,  ..., -0.0283,  0.1420, -0.0662],
        [ 0.0095,  0.0284, -0.0283,  ...,  0.1041, -0.0662, -0.0473],
        [ 0.0474,  0.1041, -0.0094,  ...,  0.0095,  0.0852, -0.0094]],
       device='cuda:0')
encoder.layer.4.attention.self.query_proj.quant.weight torch.Size([768, 768]) False
encoder.layer.4.attention.self.query_proj.right.weight torch.Size([32, 768]) True
encoder.layer.4.attention.self.query_proj.left.weight torch.Size([768, 32]) True
encoder.layer.4.attention.self.key_proj.bias torch.Size([768]) False
encoder.layer.4.attention.self.key_proj.quant.weight Parameter containing:
tensor([[ 0.0655,  0.0092, -0.0096,  ...,  0.1218,  0.1030, -0.0096],
        [ 0.0280, -0.0659,  0.1405,  ...,  0.0655, -0.0659,  0.0843],
        [ 0.0467, -0.1034,  0.0843,  ..., -0.0471, -0.0659,  0.0843],
        ...,
        [-0.0283, -0.0471, -0.0846,  ...,  0.0280, -0.1409, -0.1409],
        [-0.0096, -0.0846,  0.0655,  ..., -0.0659, -0.0283, -0.0659],
        [-0.0846,  0.0467,  0.0280,  ...,  0.0280,  0.0280,  0.1405]],
       device='cuda:0')
encoder.layer.4.attention.self.key_proj.quant.weight torch.Size([768, 768]) False
encoder.layer.4.attention.self.key_proj.right.weight torch.Size([32, 768]) True
encoder.layer.4.attention.self.key_proj.left.weight torch.Size([768, 32]) True
encoder.layer.4.attention.self.value_proj.bias torch.Size([768]) False
encoder.layer.4.attention.self.value_proj.quant.weight Parameter containing:
tensor([[-0.0458,  0.0583,  0.0323,  ..., -0.0979, -0.0849, -0.0849],
        [ 0.0583,  0.0062, -0.0588,  ..., -0.0198,  0.0843, -0.0719],
        [ 0.0062, -0.0458, -0.0198,  ..., -0.0328, -0.0458, -0.0198],
        ...,
        [-0.0198, -0.0979, -0.0328,  ...,  0.0713, -0.0979, -0.0458],
        [ 0.0974, -0.0198,  0.0583,  ..., -0.0979, -0.0198, -0.0719],
        [ 0.0974,  0.0193, -0.0588,  ..., -0.0328,  0.0062,  0.0713]],
       device='cuda:0')
encoder.layer.4.attention.self.value_proj.quant.weight torch.Size([768, 768]) False
encoder.layer.4.attention.self.value_proj.right.weight torch.Size([32, 768]) True
encoder.layer.4.attention.self.value_proj.left.weight torch.Size([768, 32]) True
encoder.layer.4.attention.output.dense.bias torch.Size([768]) False
encoder.layer.4.attention.output.dense.quant.weight Parameter containing:
tensor([[ 0.0193, -0.0064, -0.0193,  ...,  0.0193, -0.0964, -0.0964],
        [ 0.0450, -0.0064,  0.0193,  ...,  0.0321,  0.0450,  0.0064],
        [ 0.0064, -0.0064, -0.0064,  ..., -0.0321, -0.0707, -0.0707],
        ...,
        [-0.0193,  0.0064, -0.0321,  ...,  0.0193,  0.0450, -0.0193],
        [-0.0321,  0.0064, -0.0321,  ...,  0.0578, -0.0321,  0.0064],
        [-0.0578,  0.0193,  0.0450,  ...,  0.0450,  0.0835,  0.0450]],
       device='cuda:0')
encoder.layer.4.attention.output.dense.quant.weight torch.Size([768, 768]) False
encoder.layer.4.attention.output.dense.right.weight torch.Size([32, 768]) True
encoder.layer.4.attention.output.dense.left.weight torch.Size([768, 32]) True
encoder.layer.4.attention.output.LayerNorm.weight torch.Size([768]) False
encoder.layer.4.attention.output.LayerNorm.bias torch.Size([768]) False
encoder.layer.4.intermediate.dense.bias torch.Size([3072]) False
encoder.layer.4.intermediate.dense.quant.weight Parameter containing:
tensor([[-0.0050, -0.0050,  0.0093,  ..., -0.0194, -0.0194, -0.0194],
        [-0.0194, -0.0194, -0.0194,  ...,  0.0093, -0.0050, -0.0194],
        [ 0.0236,  0.0380, -0.1054,  ...,  0.0093, -0.0337, -0.0337],
        ...,
        [-0.0194, -0.0624,  0.0380,  ..., -0.0194,  0.0380,  0.0523],
        [ 0.0380, -0.0194, -0.0194,  ..., -0.0050, -0.0624, -0.0050],
        [ 0.0236,  0.0380,  0.0236,  ...,  0.0093, -0.0481, -0.0050]],
       device='cuda:0')
encoder.layer.4.intermediate.dense.quant.weight torch.Size([3072, 768]) False
encoder.layer.4.intermediate.dense.right.weight torch.Size([32, 768]) True
encoder.layer.4.intermediate.dense.left.weight torch.Size([3072, 32]) True
encoder.layer.4.output.dense.bias torch.Size([768]) False
encoder.layer.4.output.dense.quant.weight Parameter containing:
tensor([[-0.0203, -0.0068,  0.0068,  ..., -0.0609, -0.0338, -0.0474],
        [-0.0068,  0.0338,  0.0338,  ...,  0.0474,  0.0338, -0.0203],
        [ 0.0068,  0.0068,  0.0338,  ..., -0.0068, -0.0068,  0.1015],
        ...,
        [ 0.0203,  0.0068,  0.0203,  ..., -0.0068,  0.0068,  0.0068],
        [ 0.0203,  0.0744, -0.1015,  ...,  0.0203, -0.0474,  0.0474],
        [ 0.0474, -0.0068,  0.0068,  ..., -0.0609, -0.0338, -0.0068]],
       device='cuda:0')
encoder.layer.4.output.dense.quant.weight torch.Size([768, 3072]) False
encoder.layer.4.output.dense.right.weight torch.Size([32, 3072]) True
encoder.layer.4.output.dense.left.weight torch.Size([768, 32]) True
encoder.layer.4.output.LayerNorm.weight torch.Size([768]) False
encoder.layer.4.output.LayerNorm.bias torch.Size([768]) False
encoder.layer.5.attention.self.query_proj.bias torch.Size([768]) False
encoder.layer.5.attention.self.query_proj.quant.weight Parameter containing:
tensor([[ 0.0098,  0.1256,  0.0677,  ...,  0.0870,  0.0677, -0.0095],
        [-0.0095,  0.0098, -0.1254,  ..., -0.0289, -0.0095, -0.0095],
        [-0.0482,  0.0291, -0.0482,  ..., -0.0095,  0.1449, -0.0675],
        ...,
        [ 0.0098, -0.0095, -0.0095,  ..., -0.0868,  0.0677, -0.1061],
        [-0.0675, -0.0095, -0.0095,  ..., -0.0095,  0.0484,  0.0098],
        [-0.0482, -0.0095,  0.0677,  ...,  0.0291,  0.0484, -0.0095]],
       device='cuda:0')
encoder.layer.5.attention.self.query_proj.quant.weight torch.Size([768, 768]) False
encoder.layer.5.attention.self.query_proj.right.weight torch.Size([32, 768]) True
encoder.layer.5.attention.self.query_proj.left.weight torch.Size([768, 32]) True
encoder.layer.5.attention.self.key_proj.bias torch.Size([768]) False
encoder.layer.5.attention.self.key_proj.quant.weight Parameter containing:
tensor([[ 0.0286, -0.0289, -0.0097,  ...,  0.0478, -0.1055,  0.1435],
        [ 0.0478, -0.0289, -0.1247,  ...,  0.0094,  0.0094,  0.0094],
        [ 0.0669,  0.0094, -0.0480,  ..., -0.0863, -0.0863, -0.0480],
        ...,
        [ 0.0478, -0.0097,  0.1435,  ..., -0.0863, -0.0289, -0.0097],
        [ 0.0478, -0.0289, -0.0097,  ..., -0.0672,  0.0861, -0.0672],
        [-0.0097,  0.0861, -0.0097,  ...,  0.0478,  0.0286, -0.0672]],
       device='cuda:0')
encoder.layer.5.attention.self.key_proj.quant.weight torch.Size([768, 768]) False
encoder.layer.5.attention.self.key_proj.right.weight torch.Size([32, 768]) True
encoder.layer.5.attention.self.key_proj.left.weight torch.Size([768, 32]) True
encoder.layer.5.attention.self.value_proj.bias torch.Size([768]) False
encoder.layer.5.attention.self.value_proj.quant.weight Parameter containing:
tensor([[-0.0298, -0.0298, -0.0536,  ..., -0.0061, -0.0655,  0.0652],
        [-0.0180,  0.0177, -0.0417,  ...,  0.0415, -0.0180, -0.0298],
        [-0.0536, -0.0893, -0.0180,  ..., -0.0536, -0.0061, -0.0298],
        ...,
        [-0.0893, -0.0061, -0.0893,  ..., -0.0180,  0.0177, -0.0180],
        [ 0.0890, -0.0655, -0.0061,  ..., -0.0061, -0.0893,  0.0296],
        [-0.0298, -0.0774, -0.0417,  ..., -0.0774,  0.0890, -0.0298]],
       device='cuda:0')
encoder.layer.5.attention.self.value_proj.quant.weight torch.Size([768, 768]) False
encoder.layer.5.attention.self.value_proj.right.weight torch.Size([32, 768]) True
encoder.layer.5.attention.self.value_proj.left.weight torch.Size([768, 32]) True
encoder.layer.5.attention.output.dense.bias torch.Size([768]) False
encoder.layer.5.attention.output.dense.quant.weight Parameter containing:
tensor([[ 0.0060, -0.0301, -0.0421,  ...,  0.0662, -0.0662,  0.0060],
        [ 0.0542, -0.0180,  0.0421,  ...,  0.0662,  0.0782,  0.0782],
        [-0.0541, -0.0180, -0.0301,  ...,  0.0903, -0.0421,  0.0181],
        ...,
        [-0.0180,  0.0301,  0.0181,  ...,  0.0421, -0.0060,  0.0301],
        [-0.0902, -0.0180, -0.0902,  ..., -0.0541,  0.0421,  0.0903],
        [ 0.0421, -0.0662, -0.0060,  ...,  0.0301, -0.0060, -0.0060]],
       device='cuda:0')
encoder.layer.5.attention.output.dense.quant.weight torch.Size([768, 768]) False
encoder.layer.5.attention.output.dense.right.weight torch.Size([32, 768]) True
encoder.layer.5.attention.output.dense.left.weight torch.Size([768, 32]) True
encoder.layer.5.attention.output.LayerNorm.weight torch.Size([768]) False
encoder.layer.5.attention.output.LayerNorm.bias torch.Size([768]) False
encoder.layer.5.intermediate.dense.bias torch.Size([3072]) False
encoder.layer.5.intermediate.dense.quant.weight Parameter containing:
tensor([[-0.0461, -0.0047,  0.0091,  ..., -0.0461,  0.0229, -0.0185],
        [ 0.0505,  0.0367,  0.0367,  ..., -0.0047,  0.0919, -0.0047],
        [ 0.0091,  0.0091, -0.0323,  ..., -0.0185,  0.0781,  0.0229],
        ...,
        [ 0.0091,  0.0229, -0.0875,  ...,  0.0505, -0.1013, -0.0323],
        [-0.0047,  0.0229,  0.0367,  ...,  0.0091,  0.0091,  0.0367],
        [-0.0737, -0.0185, -0.0461,  ..., -0.0323, -0.0047,  0.0367]],
       device='cuda:0')
encoder.layer.5.intermediate.dense.quant.weight torch.Size([3072, 768]) False
encoder.layer.5.intermediate.dense.right.weight torch.Size([32, 768]) True
encoder.layer.5.intermediate.dense.left.weight torch.Size([3072, 32]) True
encoder.layer.5.output.dense.bias torch.Size([768]) False
encoder.layer.5.output.dense.quant.weight Parameter containing:
tensor([[-0.0064, -0.0064, -0.0322,  ...,  0.0193, -0.0322, -0.0064],
        [ 0.0322,  0.0193,  0.0451,  ..., -0.0322,  0.0065,  0.0065],
        [-0.0064, -0.0580, -0.0451,  ..., -0.0451,  0.0322,  0.0967],
        ...,
        [ 0.0065,  0.0065,  0.0065,  ..., -0.0193, -0.0322, -0.0193],
        [ 0.0580,  0.0967,  0.0580,  ..., -0.0451, -0.0193,  0.0065],
        [-0.0193, -0.0451,  0.0193,  ..., -0.0193, -0.0322, -0.0451]],
       device='cuda:0')
encoder.layer.5.output.dense.quant.weight torch.Size([768, 3072]) False
encoder.layer.5.output.dense.right.weight torch.Size([32, 3072]) True
encoder.layer.5.output.dense.left.weight torch.Size([768, 32]) True
encoder.layer.5.output.LayerNorm.weight torch.Size([768]) False
encoder.layer.5.output.LayerNorm.bias torch.Size([768]) False
encoder.layer.6.attention.self.query_proj.bias torch.Size([768]) False
encoder.layer.6.attention.self.query_proj.quant.weight Parameter containing:
tensor([[ 0.0481,  0.0286, -0.0687,  ..., -0.0298,  0.0481, -0.0881],
        [ 0.0092, -0.0881, -0.0298,  ...,  0.0676,  0.0092,  0.0286],
        [ 0.0286, -0.0298, -0.0492,  ...,  0.0481,  0.0481,  0.0870],
        ...,
        [ 0.0286,  0.0286, -0.0881,  ..., -0.1465, -0.1076, -0.1465],
        [ 0.0870, -0.0298,  0.0481,  ...,  0.0481, -0.0103, -0.0881],
        [ 0.0286,  0.0092,  0.1454,  ...,  0.0286,  0.0481,  0.1454]],
       device='cuda:0')
encoder.layer.6.attention.self.query_proj.quant.weight torch.Size([768, 768]) False
encoder.layer.6.attention.self.query_proj.right.weight torch.Size([32, 768]) True
encoder.layer.6.attention.self.query_proj.left.weight torch.Size([768, 32]) True
encoder.layer.6.attention.self.key_proj.bias torch.Size([768]) False
encoder.layer.6.attention.self.key_proj.quant.weight Parameter containing:
tensor([[-0.0672, -0.0093,  0.1452,  ..., -0.0479, -0.1058, -0.0672],
        [ 0.1066,  0.0100,  0.0487,  ...,  0.0487, -0.0093,  0.0100],
        [ 0.0487,  0.0487,  0.0100,  ...,  0.0100,  0.0487,  0.0100],
        ...,
        [ 0.0680,  0.0294, -0.0865,  ..., -0.1058, -0.0672, -0.1444],
        [ 0.0680, -0.0286,  0.0680,  ...,  0.0100,  0.0487, -0.0479],
        [ 0.1066,  0.1066,  0.0100,  ..., -0.0093,  0.0873,  0.1452]],
       device='cuda:0')
encoder.layer.6.attention.self.key_proj.quant.weight torch.Size([768, 768]) False
encoder.layer.6.attention.self.key_proj.right.weight torch.Size([32, 768]) True
encoder.layer.6.attention.self.key_proj.left.weight torch.Size([768, 32]) True
encoder.layer.6.attention.self.value_proj.bias torch.Size([768]) False
encoder.layer.6.attention.self.value_proj.quant.weight Parameter containing:
tensor([[ 0.0510,  0.0850,  0.0736,  ..., -0.0171, -0.0285,  0.0056],
        [-0.0171, -0.0171, -0.0852,  ...,  0.0623, -0.0398, -0.0852],
        [-0.0512,  0.0736, -0.0512,  ..., -0.0058, -0.0398, -0.0285],
        ...,
        [ 0.0056, -0.0058, -0.0171,  ..., -0.0058, -0.0171, -0.0058],
        [-0.0171, -0.0171,  0.0169,  ...,  0.0169, -0.0625, -0.0171],
        [ 0.0169, -0.0171,  0.0169,  ...,  0.0056,  0.0169, -0.0171]],
       device='cuda:0')
encoder.layer.6.attention.self.value_proj.quant.weight torch.Size([768, 768]) False
encoder.layer.6.attention.self.value_proj.right.weight torch.Size([32, 768]) True
encoder.layer.6.attention.self.value_proj.left.weight torch.Size([768, 32]) True
encoder.layer.6.attention.output.dense.bias torch.Size([768]) False
encoder.layer.6.attention.output.dense.quant.weight Parameter containing:
tensor([[-0.0174, -0.0174, -0.0637,  ..., -0.0174,  0.0173,  0.0173],
        [-0.0174, -0.0868,  0.0289,  ..., -0.0058, -0.0058, -0.0174],
        [ 0.0636, -0.0289, -0.0868,  ...,  0.0058,  0.0058,  0.0867],
        ...,
        [ 0.0289, -0.0174,  0.0058,  ..., -0.0174,  0.0173, -0.0058],
        [-0.0174,  0.0173, -0.0868,  ..., -0.0752,  0.0289,  0.0058],
        [-0.0058,  0.0173, -0.0058,  ..., -0.0174,  0.0289,  0.0289]],
       device='cuda:0')
encoder.layer.6.attention.output.dense.quant.weight torch.Size([768, 768]) False
encoder.layer.6.attention.output.dense.right.weight torch.Size([32, 768]) True
encoder.layer.6.attention.output.dense.left.weight torch.Size([768, 32]) True
encoder.layer.6.attention.output.LayerNorm.weight torch.Size([768]) False
encoder.layer.6.attention.output.LayerNorm.bias torch.Size([768]) False
encoder.layer.6.intermediate.dense.bias torch.Size([3072]) False
encoder.layer.6.intermediate.dense.quant.weight Parameter containing:
tensor([[-0.0979,  0.0355, -0.0179,  ..., -0.0712,  0.0088,  0.0088],
        [ 0.0088,  0.0355, -0.0179,  ..., -0.0445, -0.0445,  0.0221],
        [-0.0845, -0.0712, -0.1112,  ..., -0.0045,  0.0088,  0.0088],
        ...,
        [-0.0845, -0.0045,  0.0488,  ..., -0.1112, -0.0712,  0.0488],
        [-0.0312, -0.0312, -0.0179,  ..., -0.0312,  0.0355,  0.0221],
        [-0.0045,  0.0488, -0.0712,  ...,  0.0221,  0.0755, -0.0179]],
       device='cuda:0')
encoder.layer.6.intermediate.dense.quant.weight torch.Size([3072, 768]) False
encoder.layer.6.intermediate.dense.right.weight torch.Size([32, 768]) True
encoder.layer.6.intermediate.dense.left.weight torch.Size([3072, 32]) True
encoder.layer.6.output.dense.bias torch.Size([768]) False
encoder.layer.6.output.dense.quant.weight Parameter containing:
tensor([[ 0.0431,  0.0308, -0.0307,  ...,  0.0800, -0.0061, -0.0553],
        [ 0.0431, -0.0553, -0.0061,  ...,  0.0185,  0.0431, -0.0061],
        [ 0.0185,  0.0554, -0.0184,  ..., -0.0184, -0.0430,  0.0062],
        ...,
        [-0.0184, -0.0307, -0.0184,  ...,  0.0185,  0.0062,  0.0062],
        [ 0.0062,  0.0062,  0.0554,  ...,  0.0062,  0.0308,  0.0923],
        [-0.0430,  0.0062,  0.0185,  ..., -0.0184,  0.0062,  0.0308]],
       device='cuda:0')
encoder.layer.6.output.dense.quant.weight torch.Size([768, 3072]) False
encoder.layer.6.output.dense.right.weight torch.Size([32, 3072]) True
encoder.layer.6.output.dense.left.weight torch.Size([768, 32]) True
encoder.layer.6.output.LayerNorm.weight torch.Size([768]) False
encoder.layer.6.output.LayerNorm.bias torch.Size([768]) False
encoder.layer.7.attention.self.query_proj.bias torch.Size([768]) False
encoder.layer.7.attention.self.query_proj.quant.weight Parameter containing:
tensor([[-0.1071, -0.0486,  0.0488,  ...,  0.1463,  0.0099,  0.0099],
        [-0.0486,  0.0099,  0.0878,  ...,  0.0488, -0.0291,  0.0099],
        [-0.0291,  0.0488, -0.0486,  ...,  0.0488, -0.0486, -0.0486],
        ...,
        [ 0.0683,  0.0099, -0.0096,  ..., -0.0096,  0.0099, -0.0096],
        [-0.0291, -0.0876, -0.0291,  ...,  0.0294, -0.1071, -0.0096],
        [ 0.0878, -0.0876, -0.0096,  ...,  0.0683, -0.0681, -0.0291]],
       device='cuda:0')
encoder.layer.7.attention.self.query_proj.quant.weight torch.Size([768, 768]) False
encoder.layer.7.attention.self.query_proj.right.weight torch.Size([32, 768]) True
encoder.layer.7.attention.self.query_proj.left.weight torch.Size([768, 32]) True
encoder.layer.7.attention.self.key_proj.bias torch.Size([768]) False
encoder.layer.7.attention.self.key_proj.quant.weight Parameter containing:
tensor([[-0.1266, -0.0096, -0.0096,  ...,  0.0880, -0.0096, -0.0291],
        [-0.0876,  0.0294,  0.0880,  ...,  0.0880, -0.0096, -0.0096],
        [-0.1071,  0.0684, -0.0486,  ...,  0.0880, -0.0876, -0.0876],
        ...,
        [-0.0486,  0.0294,  0.0684,  ..., -0.0486,  0.0684,  0.0099],
        [-0.0291,  0.0294,  0.0294,  ...,  0.0294,  0.0489,  0.0489],
        [ 0.0489, -0.1461, -0.0291,  ...,  0.0684, -0.0096, -0.0291]],
       device='cuda:0')
encoder.layer.7.attention.self.key_proj.quant.weight torch.Size([768, 768]) False
encoder.layer.7.attention.self.key_proj.right.weight torch.Size([32, 768]) True
encoder.layer.7.attention.self.key_proj.left.weight torch.Size([768, 32]) True
encoder.layer.7.attention.self.value_proj.bias torch.Size([768]) False
encoder.layer.7.attention.self.value_proj.quant.weight Parameter containing:
tensor([[-0.0159,  0.0264, -0.0053,  ...,  0.0158, -0.0371,  0.0582],
        [ 0.0052, -0.0159,  0.0370,  ...,  0.0158, -0.0265, -0.0265],
        [-0.0159, -0.0159,  0.0264,  ..., -0.0159, -0.0053, -0.0053],
        ...,
        [ 0.0158,  0.0582, -0.0053,  ...,  0.0264, -0.0053, -0.0477],
        [ 0.0370, -0.0159,  0.0582,  ...,  0.0158, -0.0053, -0.0159],
        [-0.0053,  0.0264, -0.0265,  ...,  0.0052,  0.0476,  0.0476]],
       device='cuda:0')
encoder.layer.7.attention.self.value_proj.quant.weight torch.Size([768, 768]) False
encoder.layer.7.attention.self.value_proj.right.weight torch.Size([32, 768]) True
encoder.layer.7.attention.self.value_proj.left.weight torch.Size([768, 32]) True
encoder.layer.7.attention.output.dense.bias torch.Size([768]) False
encoder.layer.7.attention.output.dense.quant.weight Parameter containing:
tensor([[-0.0055,  0.0055,  0.0055,  ...,  0.0055, -0.0276,  0.0165],
        [ 0.0055,  0.0496, -0.0055,  ...,  0.0276, -0.0386,  0.0386],
        [ 0.0827,  0.0827, -0.0386,  ..., -0.0606, -0.0606, -0.0055],
        ...,
        [ 0.0165,  0.0055,  0.0055,  ..., -0.0055, -0.0055, -0.0055],
        [ 0.0827, -0.0827, -0.0276,  ...,  0.0165, -0.0496, -0.0386],
        [ 0.0386, -0.0276, -0.0055,  ..., -0.0165,  0.0055, -0.0165]],
       device='cuda:0')
encoder.layer.7.attention.output.dense.quant.weight torch.Size([768, 768]) False
encoder.layer.7.attention.output.dense.right.weight torch.Size([32, 768]) True
encoder.layer.7.attention.output.dense.left.weight torch.Size([768, 32]) True
encoder.layer.7.attention.output.LayerNorm.weight torch.Size([768]) False
encoder.layer.7.attention.output.LayerNorm.bias torch.Size([768]) False
encoder.layer.7.intermediate.dense.bias torch.Size([3072]) False
encoder.layer.7.intermediate.dense.quant.weight Parameter containing:
tensor([[-0.0819,  0.0744, -0.0298,  ...,  0.0483, -0.0428, -0.0038],
        [ 0.0093, -0.1079, -0.0168,  ...,  0.0483, -0.0168, -0.0038],
        [ 0.0483,  0.0223, -0.0038,  ..., -0.0168, -0.0298, -0.0168],
        ...,
        [-0.0298,  0.0483, -0.0168,  ...,  0.0614, -0.0428,  0.0353],
        [ 0.0874, -0.0038, -0.0038,  ...,  0.0614, -0.0168, -0.0689],
        [ 0.0874, -0.0298,  0.0223,  ..., -0.0168,  0.0093, -0.0428]],
       device='cuda:0')
encoder.layer.7.intermediate.dense.quant.weight torch.Size([3072, 768]) False
encoder.layer.7.intermediate.dense.right.weight torch.Size([32, 768]) True
encoder.layer.7.intermediate.dense.left.weight torch.Size([3072, 32]) True
encoder.layer.7.output.dense.bias torch.Size([768]) False
encoder.layer.7.output.dense.quant.weight Parameter containing:
tensor([[ 0.0299, -0.0059, -0.0059,  ...,  0.0537,  0.0299,  0.0060],
        [ 0.0299, -0.0656,  0.0537,  ..., -0.0418, -0.0895, -0.0179],
        [-0.0298,  0.0657,  0.0896,  ...,  0.0657,  0.0657,  0.0179],
        ...,
        [ 0.0537,  0.0299,  0.0299,  ...,  0.0299, -0.0179, -0.0179],
        [ 0.0179,  0.0896, -0.0179,  ...,  0.0537, -0.0656, -0.0776],
        [ 0.0776,  0.0060, -0.0298,  ..., -0.0059,  0.0299, -0.0179]],
       device='cuda:0')
encoder.layer.7.output.dense.quant.weight torch.Size([768, 3072]) False
encoder.layer.7.output.dense.right.weight torch.Size([32, 3072]) True
encoder.layer.7.output.dense.left.weight torch.Size([768, 32]) True
encoder.layer.7.output.LayerNorm.weight torch.Size([768]) False
encoder.layer.7.output.LayerNorm.bias torch.Size([768]) False
encoder.layer.8.attention.self.query_proj.bias torch.Size([768]) False
encoder.layer.8.attention.self.query_proj.quant.weight Parameter containing:
tensor([[ 0.0085, -0.1484, -0.0307,  ..., -0.0503,  0.0281,  0.0281],
        [-0.1092,  0.0478,  0.0674,  ...,  0.0870,  0.0674, -0.0307],
        [-0.0307,  0.0478,  0.1262,  ...,  0.1066,  0.0478, -0.0111],
        ...,
        [ 0.0478, -0.0307,  0.0674,  ...,  0.0674,  0.0478,  0.1066],
        [-0.0503,  0.0281, -0.0307,  ..., -0.0111, -0.0896,  0.0870],
        [ 0.0478, -0.0111,  0.0085,  ...,  0.0281, -0.1288, -0.0503]],
       device='cuda:0')
encoder.layer.8.attention.self.query_proj.quant.weight torch.Size([768, 768]) False
encoder.layer.8.attention.self.query_proj.right.weight torch.Size([32, 768]) True
encoder.layer.8.attention.self.query_proj.left.weight torch.Size([768, 32]) True
encoder.layer.8.attention.self.key_proj.bias torch.Size([768]) False
encoder.layer.8.attention.self.key_proj.quant.weight Parameter containing:
tensor([[ 0.0304, -0.0478, -0.0674,  ...,  0.0108, -0.1455,  0.0694],
        [-0.0478,  0.0108,  0.1476,  ...,  0.0499,  0.0890,  0.0108],
        [-0.0869, -0.0283,  0.0499,  ...,  0.0890,  0.1281, -0.0869],
        ...,
        [-0.1455, -0.0674,  0.1281,  ...,  0.0304,  0.1476, -0.0869],
        [-0.0283, -0.0478, -0.0478,  ..., -0.0283, -0.0674,  0.0890],
        [-0.0087, -0.0478,  0.0304,  ...,  0.0108, -0.0283, -0.1260]],
       device='cuda:0')
encoder.layer.8.attention.self.key_proj.quant.weight torch.Size([768, 768]) False
encoder.layer.8.attention.self.key_proj.right.weight torch.Size([32, 768]) True
encoder.layer.8.attention.self.key_proj.left.weight torch.Size([768, 32]) True
encoder.layer.8.attention.self.value_proj.bias torch.Size([768]) False
encoder.layer.8.attention.self.value_proj.quant.weight Parameter containing:
tensor([[ 0.0052,  0.0052, -0.0355,  ...,  0.0357,  0.0458,  0.0153],
        [-0.0050, -0.0253, -0.0355,  ...,  0.0052, -0.0152,  0.0052],
        [-0.0152,  0.0153,  0.0052,  ...,  0.0052, -0.0558,  0.0458],
        ...,
        [ 0.0560,  0.0357,  0.0153,  ..., -0.0457,  0.0052, -0.0050],
        [ 0.0052, -0.0050, -0.0253,  ...,  0.0052, -0.0355,  0.0153],
        [-0.0660,  0.0255, -0.0355,  ..., -0.0152,  0.0052,  0.0153]],
       device='cuda:0')
encoder.layer.8.attention.self.value_proj.quant.weight torch.Size([768, 768]) False
encoder.layer.8.attention.self.value_proj.right.weight torch.Size([32, 768]) True
encoder.layer.8.attention.self.value_proj.left.weight torch.Size([768, 32]) True
encoder.layer.8.attention.output.dense.bias torch.Size([768]) False
encoder.layer.8.attention.output.dense.quant.weight Parameter containing:
tensor([[-0.0054, -0.0377,  0.0269,  ...,  0.0269,  0.0269,  0.0054],
        [-0.0054, -0.0054,  0.0161,  ..., -0.0377, -0.0485, -0.0270],
        [-0.0485, -0.0270, -0.0162,  ...,  0.0161, -0.0485,  0.0700],
        ...,
        [-0.0162,  0.0054,  0.0054,  ..., -0.0054, -0.0054, -0.0162],
        [ 0.0377,  0.0269, -0.0162,  ...,  0.0808, -0.0593, -0.0162],
        [ 0.0269,  0.0054,  0.0161,  ..., -0.0162,  0.0054,  0.0269]],
       device='cuda:0')
encoder.layer.8.attention.output.dense.quant.weight torch.Size([768, 768]) False
encoder.layer.8.attention.output.dense.right.weight torch.Size([32, 768]) True
encoder.layer.8.attention.output.dense.left.weight torch.Size([768, 32]) True
encoder.layer.8.attention.output.LayerNorm.weight torch.Size([768]) False
encoder.layer.8.attention.output.LayerNorm.bias torch.Size([768]) False
encoder.layer.8.intermediate.dense.bias torch.Size([3072]) False
encoder.layer.8.intermediate.dense.quant.weight Parameter containing:
tensor([[-0.0949, -0.0160, -0.0160,  ..., -0.0160, -0.0686, -0.0291],
        [ 0.0498, -0.0423,  0.0103,  ...,  0.0235, -0.0949,  0.0366],
        [-0.0028,  0.0235, -0.0028,  ...,  0.0235,  0.0103, -0.0423],
        ...,
        [-0.0028, -0.0423, -0.0028,  ...,  0.0498, -0.0160, -0.0554],
        [-0.0028, -0.0160, -0.0817,  ..., -0.0291, -0.0028,  0.0366],
        [-0.0949,  0.0103,  0.0235,  ..., -0.0160, -0.0160, -0.0028]],
       device='cuda:0')
encoder.layer.8.intermediate.dense.quant.weight torch.Size([3072, 768]) False
encoder.layer.8.intermediate.dense.right.weight torch.Size([32, 768]) True
encoder.layer.8.intermediate.dense.left.weight torch.Size([3072, 32]) True
encoder.layer.8.output.dense.bias torch.Size([768]) False
encoder.layer.8.output.dense.quant.weight Parameter containing:
tensor([[-0.0539,  0.0539, -0.0299,  ..., -0.0180, -0.0060,  0.0658],
        [ 0.0060,  0.0179, -0.0060,  ..., -0.0419, -0.0898, -0.0299],
        [ 0.0299,  0.0778, -0.0299,  ...,  0.0179, -0.0419, -0.0419],
        ...,
        [ 0.0060, -0.0060,  0.0299,  ...,  0.0060,  0.0179, -0.0060],
        [-0.0898,  0.0419, -0.0180,  ..., -0.0778,  0.0658, -0.0299],
        [-0.0299, -0.0060, -0.0060,  ..., -0.0419,  0.0299, -0.0180]],
       device='cuda:0')
encoder.layer.8.output.dense.quant.weight torch.Size([768, 3072]) False
encoder.layer.8.output.dense.right.weight torch.Size([32, 3072]) True
encoder.layer.8.output.dense.left.weight torch.Size([768, 32]) True
encoder.layer.8.output.LayerNorm.weight torch.Size([768]) False
encoder.layer.8.output.LayerNorm.bias torch.Size([768]) False
encoder.layer.9.attention.self.query_proj.bias torch.Size([768]) False
encoder.layer.9.attention.self.query_proj.quant.weight Parameter containing:
tensor([[-0.0096, -0.0096, -0.0687,  ..., -0.0293,  0.0299,  0.0299],
        [ 0.0496,  0.0299, -0.0293,  ..., -0.0687,  0.0102, -0.0884],
        [-0.0096, -0.0293, -0.0884,  ...,  0.0102, -0.1082, -0.0884],
        ...,
        [-0.0490, -0.0687,  0.0693,  ..., -0.0490,  0.0693, -0.0884],
        [-0.0293,  0.0496, -0.0490,  ...,  0.0890, -0.1082, -0.0884],
        [ 0.0299,  0.0299, -0.0884,  ...,  0.0299,  0.0299, -0.0884]],
       device='cuda:0')
encoder.layer.9.attention.self.query_proj.quant.weight torch.Size([768, 768]) False
encoder.layer.9.attention.self.query_proj.right.weight torch.Size([32, 768]) True
encoder.layer.9.attention.self.query_proj.left.weight torch.Size([768, 32]) True
encoder.layer.9.attention.self.key_proj.bias torch.Size([768]) False
encoder.layer.9.attention.self.key_proj.quant.weight Parameter containing:
tensor([[ 0.0284,  0.0284, -0.1472,  ..., -0.0106,  0.0480, -0.0496],
        [-0.0106, -0.0692, -0.0106,  ..., -0.0887, -0.0106, -0.0496],
        [ 0.0284, -0.0887, -0.1277,  ..., -0.0301, -0.1472,  0.0089],
        ...,
        [-0.0496,  0.0089,  0.0284,  ..., -0.1277, -0.0106,  0.0089],
        [-0.0887, -0.0106, -0.0106,  ..., -0.0496,  0.0089, -0.0887],
        [ 0.0089,  0.0089, -0.1472,  ...,  0.0284, -0.0887, -0.0106]],
       device='cuda:0')
encoder.layer.9.attention.self.key_proj.quant.weight torch.Size([768, 768]) False
encoder.layer.9.attention.self.key_proj.right.weight torch.Size([32, 768]) True
encoder.layer.9.attention.self.key_proj.left.weight torch.Size([768, 32]) True
encoder.layer.9.attention.self.value_proj.bias torch.Size([768]) False
encoder.layer.9.attention.self.value_proj.quant.weight Parameter containing:
tensor([[-0.0331,  0.0200, -0.0198,  ..., -0.0065, -0.0994, -0.0065],
        [ 0.0200, -0.0729, -0.0198,  ...,  0.0068,  0.0333,  0.0598],
        [-0.0331, -0.0065, -0.0994,  ..., -0.0198,  0.0997,  0.0997],
        ...,
        [ 0.0068,  0.0200, -0.0331,  ...,  0.0068,  0.0731,  0.0333],
        [ 0.0864, -0.0463,  0.0997,  ...,  0.0200, -0.0463,  0.0333],
        [ 0.0200, -0.0198,  0.0333,  ..., -0.0198,  0.0466,  0.0068]],
       device='cuda:0')
encoder.layer.9.attention.self.value_proj.quant.weight torch.Size([768, 768]) False
encoder.layer.9.attention.self.value_proj.right.weight torch.Size([32, 768]) True
encoder.layer.9.attention.self.value_proj.left.weight torch.Size([768, 32]) True
encoder.layer.9.attention.output.dense.bias torch.Size([768]) False
encoder.layer.9.attention.output.dense.quant.weight Parameter containing:
tensor([[ 0.0065,  0.0065, -0.0588,  ..., -0.0588, -0.0979,  0.0195],
        [ 0.0848, -0.0457,  0.0717,  ...,  0.0065, -0.0457, -0.0066],
        [ 0.0326,  0.0456, -0.0979,  ...,  0.0587,  0.0065, -0.0849],
        ...,
        [ 0.0065,  0.0065, -0.0066,  ...,  0.0065, -0.0066,  0.0065],
        [-0.0457, -0.0196, -0.0718,  ...,  0.0978,  0.0848,  0.0195],
        [-0.0066,  0.0195,  0.0195,  ...,  0.0065, -0.0066,  0.0065]],
       device='cuda:0')
encoder.layer.9.attention.output.dense.quant.weight torch.Size([768, 768]) False
encoder.layer.9.attention.output.dense.right.weight torch.Size([32, 768]) True
encoder.layer.9.attention.output.dense.left.weight torch.Size([768, 32]) True
encoder.layer.9.attention.output.LayerNorm.weight torch.Size([768]) False
encoder.layer.9.attention.output.LayerNorm.bias torch.Size([768]) False
encoder.layer.9.intermediate.dense.bias torch.Size([3072]) False
encoder.layer.9.intermediate.dense.quant.weight Parameter containing:
tensor([[-0.1113, -0.0840, -0.1113,  ..., -0.0296, -0.1113, -0.0432],
        [ 0.0794, -0.0023, -0.0023,  ...,  0.0658, -0.0159, -0.0432],
        [ 0.0113, -0.0432, -0.0704,  ...,  0.0113, -0.0704, -0.0023],
        ...,
        [-0.0704, -0.0296,  0.0113,  ...,  0.0386,  0.0386, -0.0023],
        [-0.0159, -0.0296, -0.1113,  ...,  0.0249,  0.0522,  0.0522],
        [-0.1113, -0.0568,  0.0658,  ..., -0.0432, -0.0840,  0.0113]],
       device='cuda:0')
encoder.layer.9.intermediate.dense.quant.weight torch.Size([3072, 768]) False
encoder.layer.9.intermediate.dense.right.weight torch.Size([32, 768]) True
encoder.layer.9.intermediate.dense.left.weight torch.Size([3072, 32]) True
encoder.layer.9.output.dense.bias torch.Size([768]) False
encoder.layer.9.output.dense.quant.weight Parameter containing:
tensor([[-0.0431, -0.0062, -0.0185,  ...,  0.0061, -0.0554,  0.0554],
        [-0.0923, -0.0308, -0.0062,  ..., -0.0185,  0.0308,  0.0184],
        [-0.0923, -0.0062,  0.0923,  ..., -0.0185, -0.0431, -0.0062],
        ...,
        [ 0.0431, -0.0308,  0.0061,  ..., -0.0062,  0.0184,  0.0308],
        [-0.0923, -0.0062,  0.0677,  ...,  0.0431, -0.0308, -0.0800],
        [ 0.0061,  0.0308, -0.0185,  ..., -0.0185,  0.0554,  0.0061]],
       device='cuda:0')
encoder.layer.9.output.dense.quant.weight torch.Size([768, 3072]) False
encoder.layer.9.output.dense.right.weight torch.Size([32, 3072]) True
encoder.layer.9.output.dense.left.weight torch.Size([768, 32]) True
encoder.layer.9.output.LayerNorm.weight torch.Size([768]) False
encoder.layer.9.output.LayerNorm.bias torch.Size([768]) False
encoder.layer.10.attention.self.query_proj.bias torch.Size([768]) False
encoder.layer.10.attention.self.query_proj.quant.weight Parameter containing:
tensor([[ 0.0296,  0.1090, -0.0101,  ..., -0.0300, -0.1492, -0.0101],
        [-0.0498,  0.0892,  0.0097,  ..., -0.0101,  0.0495, -0.0101],
        [ 0.0495,  0.1289, -0.0697,  ..., -0.0498,  0.0693,  0.0097],
        ...,
        [-0.0697,  0.0296,  0.0892,  ..., -0.0498,  0.0693, -0.0101],
        [-0.1094,  0.0495, -0.1492,  ..., -0.1492, -0.1094,  0.1090],
        [-0.0498, -0.0498,  0.0892,  ..., -0.0697, -0.0896, -0.1492]],
       device='cuda:0')
encoder.layer.10.attention.self.query_proj.quant.weight torch.Size([768, 768]) False
encoder.layer.10.attention.self.query_proj.right.weight torch.Size([32, 768]) True
encoder.layer.10.attention.self.query_proj.left.weight torch.Size([768, 32]) True
encoder.layer.10.attention.self.key_proj.bias torch.Size([768]) False
encoder.layer.10.attention.self.key_proj.quant.weight Parameter containing:
tensor([[-0.0095,  0.0692,  0.0102,  ...,  0.0299, -0.0685,  0.0102],
        [-0.0488, -0.0685,  0.0299,  ..., -0.0095,  0.0102, -0.0488],
        [ 0.0102, -0.0488, -0.1275,  ..., -0.0292, -0.1472, -0.0882],
        ...,
        [-0.0488,  0.0692,  0.1086,  ..., -0.0685,  0.1086,  0.0692],
        [-0.1275,  0.1086, -0.1472,  ..., -0.1275,  0.0102,  0.0692],
        [-0.1079,  0.1086,  0.0299,  ..., -0.0882,  0.0495, -0.1079]],
       device='cuda:0')
encoder.layer.10.attention.self.key_proj.quant.weight torch.Size([768, 768]) False
encoder.layer.10.attention.self.key_proj.right.weight torch.Size([32, 768]) True
encoder.layer.10.attention.self.key_proj.left.weight torch.Size([768, 32]) True
encoder.layer.10.attention.self.value_proj.bias torch.Size([768]) False
encoder.layer.10.attention.self.value_proj.quant.weight Parameter containing:
tensor([[ 0.0665,  0.0423,  0.0423,  ..., -0.0182, -0.0182,  0.0302],
        [-0.0545, -0.0303,  0.0302,  ...,  0.0302,  0.0302,  0.0302],
        [-0.0303, -0.0424,  0.0060,  ...,  0.0302,  0.0060, -0.0424],
        ...,
        [-0.0182,  0.0181, -0.0061,  ..., -0.0061, -0.0061, -0.0182],
        [-0.0666, -0.0424,  0.0786,  ...,  0.0060,  0.0060,  0.0907],
        [ 0.0060,  0.0423, -0.0424,  ..., -0.0424,  0.0423,  0.0423]],
       device='cuda:0')
encoder.layer.10.attention.self.value_proj.quant.weight torch.Size([768, 768]) False
encoder.layer.10.attention.self.value_proj.right.weight torch.Size([32, 768]) True
encoder.layer.10.attention.self.value_proj.left.weight torch.Size([768, 32]) True
encoder.layer.10.attention.output.dense.bias torch.Size([768]) False
encoder.layer.10.attention.output.dense.quant.weight Parameter containing:
tensor([[-0.0892,  0.0178,  0.0297,  ..., -0.0178,  0.0416,  0.0059],
        [ 0.0059,  0.0297,  0.0297,  ..., -0.0892,  0.0654,  0.0178],
        [-0.0178, -0.0297, -0.0416,  ...,  0.0178,  0.0535,  0.0059],
        ...,
        [ 0.0059,  0.0297, -0.0060,  ...,  0.0297,  0.0178,  0.0059],
        [ 0.0416,  0.0297,  0.0416,  ...,  0.0535, -0.0535,  0.0892],
        [ 0.0059, -0.0178,  0.0297,  ..., -0.0178, -0.0297, -0.0297]],
       device='cuda:0')
encoder.layer.10.attention.output.dense.quant.weight torch.Size([768, 768]) False
encoder.layer.10.attention.output.dense.right.weight torch.Size([32, 768]) True
encoder.layer.10.attention.output.dense.left.weight torch.Size([768, 32]) True
encoder.layer.10.attention.output.LayerNorm.weight torch.Size([768]) False
encoder.layer.10.attention.output.LayerNorm.bias torch.Size([768]) False
encoder.layer.10.intermediate.dense.bias torch.Size([3072]) False
encoder.layer.10.intermediate.dense.quant.weight Parameter containing:
tensor([[ 0.0438, -0.0313, -0.0163,  ..., -0.0163, -0.0013, -0.0464],
        [-0.0614, -0.0013, -0.0464,  ..., -0.0163, -0.0163, -0.0464],
        [ 0.0739,  0.0589, -0.0614,  ...,  0.0589, -0.0163,  0.0438],
        ...,
        [ 0.0138, -0.0163, -0.0614,  ..., -0.0013, -0.0765, -0.0013],
        [-0.0464,  0.0138, -0.0013,  ...,  0.0138, -0.0013, -0.1216],
        [-0.0464, -0.0163,  0.0589,  ...,  0.0138, -0.1065, -0.0614]],
       device='cuda:0')
encoder.layer.10.intermediate.dense.quant.weight torch.Size([3072, 768]) False
encoder.layer.10.intermediate.dense.right.weight torch.Size([32, 768]) True
encoder.layer.10.intermediate.dense.left.weight torch.Size([3072, 32]) True
encoder.layer.10.output.dense.bias torch.Size([768]) False
encoder.layer.10.output.dense.quant.weight Parameter containing:
tensor([[-0.0064, -0.0064, -0.0706,  ..., -0.0321,  0.0321,  0.0706],
        [-0.0193,  0.0577,  0.0834,  ..., -0.0449, -0.0834,  0.0834],
        [ 0.0577, -0.0963, -0.0578,  ...,  0.0192, -0.0449,  0.0064],
        ...,
        [-0.0064,  0.0449, -0.0578,  ...,  0.0064,  0.0192, -0.0449],
        [ 0.0064,  0.0064,  0.0064,  ...,  0.0064,  0.0064,  0.0962],
        [ 0.0192,  0.0064, -0.0321,  ..., -0.0449,  0.0064, -0.0449]],
       device='cuda:0')
encoder.layer.10.output.dense.quant.weight torch.Size([768, 3072]) False
encoder.layer.10.output.dense.right.weight torch.Size([32, 3072]) True
encoder.layer.10.output.dense.left.weight torch.Size([768, 32]) True
encoder.layer.10.output.LayerNorm.weight torch.Size([768]) False
encoder.layer.10.output.LayerNorm.bias torch.Size([768]) False
encoder.layer.11.attention.self.query_proj.bias torch.Size([768]) False
encoder.layer.11.attention.self.query_proj.quant.weight Parameter containing:
tensor([[-0.0101,  0.0894,  0.0297,  ..., -0.1295, -0.1494, -0.1494],
        [ 0.0297, -0.0499,  0.0695,  ..., -0.0897, -0.0300,  0.0695],
        [ 0.0098,  0.1491,  0.0098,  ..., -0.1494,  0.0496, -0.1494],
        ...,
        [ 0.0297,  0.0894,  0.0297,  ...,  0.0695,  0.0695,  0.1093],
        [ 0.0098, -0.0897, -0.0101,  ...,  0.0098, -0.0300,  0.0695],
        [-0.0499,  0.1093,  0.0695,  ...,  0.0894,  0.1292,  0.1093]],
       device='cuda:0')
encoder.layer.11.attention.self.query_proj.quant.weight torch.Size([768, 768]) False
encoder.layer.11.attention.self.query_proj.right.weight torch.Size([32, 768]) True
encoder.layer.11.attention.self.query_proj.left.weight torch.Size([768, 32]) True
encoder.layer.11.attention.self.key_proj.bias torch.Size([768]) False
encoder.layer.11.attention.self.key_proj.quant.weight Parameter containing:
tensor([[-0.0096, -0.0682, -0.0291,  ..., -0.1072, -0.0682, -0.1463],
        [-0.0486,  0.0880,  0.0295,  ..., -0.0486,  0.0685,  0.0099],
        [-0.0291,  0.0099, -0.0291,  ..., -0.0486, -0.1267, -0.0486],
        ...,
        [-0.1072,  0.0099, -0.0096,  ...,  0.0490,  0.1466, -0.0096],
        [-0.0291,  0.0490, -0.0486,  ..., -0.0486, -0.0291,  0.0295],
        [ 0.0490,  0.0295,  0.1271,  ..., -0.0486, -0.0682, -0.1072]],
       device='cuda:0')
encoder.layer.11.attention.self.key_proj.quant.weight torch.Size([768, 768]) False
encoder.layer.11.attention.self.key_proj.right.weight torch.Size([32, 768]) True
encoder.layer.11.attention.self.key_proj.left.weight torch.Size([768, 32]) True
encoder.layer.11.attention.self.value_proj.bias torch.Size([768]) False
encoder.layer.11.attention.self.value_proj.quant.weight Parameter containing:
tensor([[-0.0328, -0.0982,  0.0065,  ..., -0.0197, -0.0328,  0.0457],
        [ 0.0195,  0.0457, -0.0066,  ...,  0.0719, -0.0982,  0.0457],
        [-0.0589,  0.0065, -0.0720,  ...,  0.0065,  0.0195,  0.0065],
        ...,
        [-0.0197, -0.0197,  0.0457,  ..., -0.0066,  0.0457, -0.0197],
        [-0.0328, -0.0589, -0.0458,  ..., -0.0328,  0.0326,  0.0065],
        [ 0.0195, -0.0197, -0.0197,  ...,  0.0065,  0.0065, -0.0066]],
       device='cuda:0')
encoder.layer.11.attention.self.value_proj.quant.weight torch.Size([768, 768]) False
encoder.layer.11.attention.self.value_proj.right.weight torch.Size([32, 768]) True
encoder.layer.11.attention.self.value_proj.left.weight torch.Size([768, 32]) True
encoder.layer.11.attention.output.dense.bias torch.Size([768]) False
encoder.layer.11.attention.output.dense.quant.weight Parameter containing:
tensor([[-0.0311, -0.0684, -0.0062,  ...,  0.0062, -0.0311, -0.0311],
        [ 0.0062,  0.0311,  0.0062,  ..., -0.0186, -0.0684, -0.0186],
        [-0.0062, -0.0062, -0.0186,  ...,  0.0062, -0.0560, -0.0311],
        ...,
        [-0.0311, -0.0186,  0.0062,  ..., -0.0186,  0.0062, -0.0062],
        [-0.0186,  0.0809, -0.0311,  ...,  0.0560,  0.0933,  0.0933],
        [-0.0062, -0.0186, -0.0435,  ..., -0.0062, -0.0062, -0.0311]],
       device='cuda:0')
encoder.layer.11.attention.output.dense.quant.weight torch.Size([768, 768]) False
encoder.layer.11.attention.output.dense.right.weight torch.Size([32, 768]) True
encoder.layer.11.attention.output.dense.left.weight torch.Size([768, 32]) True
encoder.layer.11.attention.output.LayerNorm.weight torch.Size([768]) False
encoder.layer.11.attention.output.LayerNorm.bias torch.Size([768]) False
encoder.layer.11.intermediate.dense.bias torch.Size([3072]) False
encoder.layer.11.intermediate.dense.quant.weight Parameter containing:
tensor([[-0.0160,  0.0220,  0.0789,  ..., -0.0729,  0.0409,  0.0220],
        [-0.1298,  0.0030, -0.0919,  ..., -0.0160, -0.0160, -0.0160],
        [-0.0729, -0.0160,  0.0030,  ...,  0.0030, -0.0729,  0.0220],
        ...,
        [ 0.0409,  0.0030,  0.0599,  ..., -0.0350, -0.0350, -0.0350],
        [-0.0729,  0.0220,  0.0030,  ...,  0.0599,  0.0409, -0.0539],
        [-0.0729,  0.0220, -0.0729,  ...,  0.0409, -0.0160, -0.1109]],
       device='cuda:0')
encoder.layer.11.intermediate.dense.quant.weight torch.Size([3072, 768]) False
encoder.layer.11.intermediate.dense.right.weight torch.Size([32, 768]) True
encoder.layer.11.intermediate.dense.left.weight torch.Size([3072, 32]) True
encoder.layer.11.output.dense.bias torch.Size([768]) False
encoder.layer.11.output.dense.quant.weight Parameter containing:
tensor([[-0.0090,  0.0627,  0.0268,  ...,  0.0089,  0.0627,  0.0268],
        [ 0.1344, -0.0090,  0.0806,  ..., -0.0269,  0.0627, -0.0090],
        [-0.0449, -0.0986,  0.0627,  ...,  0.0268, -0.0269,  0.0089],
        ...,
        [-0.0269, -0.0090, -0.0269,  ..., -0.0449, -0.0628,  0.0448],
        [ 0.0806,  0.0268,  0.0448,  ..., -0.0986, -0.0090, -0.0986],
        [ 0.0268,  0.0089, -0.0090,  ...,  0.0268, -0.0090,  0.0268]],
       device='cuda:0')
encoder.layer.11.output.dense.quant.weight torch.Size([768, 3072]) False
encoder.layer.11.output.dense.right.weight torch.Size([32, 3072]) True
encoder.layer.11.output.dense.left.weight torch.Size([768, 32]) True
encoder.layer.11.output.LayerNorm.weight torch.Size([768]) False
encoder.layer.11.output.LayerNorm.bias torch.Size([768]) False
encoder.rel_embeddings.weight torch.Size([512, 768]) False
encoder.rel_embeddings.left torch.Size([512, 32]) True
encoder.rel_embeddings.right torch.Size([32, 768]) True
encoder.LayerNorm.weight torch.Size([768]) False
encoder.LayerNorm.bias torch.Size([768]) False
Total trainable parameters 9473152
We finetune about 0.04900631905988175 ratio of percentages
Running tokenizer on dataset:   0%|          | 0/9815 [00:00<?, ? examples/s]Running tokenizer on dataset:  20%|        | 2000/9815 [00:00<00:00, 15955.57 examples/s]Running tokenizer on dataset:  61%|    | 6000/9815 [00:00<00:00, 19680.37 examples/s]Running tokenizer on dataset: 100%|| 9815/9815 [00:00<00:00, 20746.23 examples/s]Running tokenizer on dataset: 100%|| 9815/9815 [00:00<00:00, 19885.07 examples/s]
/mainfs/lyceum/cjm1n19/LoftQ/scripts/cjm1n19/run_glue.py:497: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler()
04/23/2025 17:22:21 - WARNING - evaluate.loading - Using the latest cached version of the module from /scratch/cjm1n19/huggingface/modules/evaluate_modules/metrics/evaluate-metric--glue/05234ba7acc44554edcca0978db5fa3bc600eeee66229abe79ff9887eacaf3ed (last modified on Wed Apr 23 17:11:50 2025) since it couldn't be found locally at evaluate-metric--glue, or remotely on the Hugging Face Hub.
***** Running training *****
  Num examples = 392702
  Num Epochs = 5
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 61360
  0%|          | 0/61360 [00:00<?, ?it/s]Traceback (most recent call last):
  File "/mainfs/lyceum/cjm1n19/LoftQ/scripts/cjm1n19/run_glue.py", line 764, in <module>
    main()
  File "/mainfs/lyceum/cjm1n19/LoftQ/scripts/cjm1n19/run_glue.py", line 595, in main
    outputs = model(**batch)
              ^^^^^^^^^^^^^^
  File "/lyceum/cjm1n19/.conda/envs/comp6258_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/lyceum/cjm1n19/.conda/envs/comp6258_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/lyceum/cjm1n19/.conda/envs/comp6258_env/lib/python3.12/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py", line 1179, in forward
    outputs = self.deberta(
              ^^^^^^^^^^^^^
  File "/lyceum/cjm1n19/.conda/envs/comp6258_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/lyceum/cjm1n19/.conda/envs/comp6258_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/lyceum/cjm1n19/.conda/envs/comp6258_env/lib/python3.12/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py", line 874, in forward
    encoder_outputs = self.encoder(
                      ^^^^^^^^^^^^^
  File "/lyceum/cjm1n19/.conda/envs/comp6258_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/lyceum/cjm1n19/.conda/envs/comp6258_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/lyceum/cjm1n19/.conda/envs/comp6258_env/lib/python3.12/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py", line 674, in forward
    output_states, attn_weights = layer_module(
                                  ^^^^^^^^^^^^^
  File "/lyceum/cjm1n19/.conda/envs/comp6258_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/lyceum/cjm1n19/.conda/envs/comp6258_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/lyceum/cjm1n19/.conda/envs/comp6258_env/lib/python3.12/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py", line 442, in forward
    attention_output, att_matrix = self.attention(
                                   ^^^^^^^^^^^^^^^
  File "/lyceum/cjm1n19/.conda/envs/comp6258_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/lyceum/cjm1n19/.conda/envs/comp6258_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/lyceum/cjm1n19/.conda/envs/comp6258_env/lib/python3.12/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py", line 375, in forward
    self_output, att_matrix = self.self(
                              ^^^^^^^^^^
  File "/lyceum/cjm1n19/.conda/envs/comp6258_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/lyceum/cjm1n19/.conda/envs/comp6258_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/lyceum/cjm1n19/.conda/envs/comp6258_env/lib/python3.12/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py", line 267, in forward
    attention_scores = attention_scores.masked_fill(~(attention_mask), torch.finfo(query_layer.dtype).min)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: value cannot be converted to type at::Half without overflow
  0%|          | 0/61360 [00:01<?, ?it/s]
==============================================================================
Running epilogue script on pink51.

Submit time  : 2025-04-23T17:19:35
Start time   : 2025-04-23T17:19:37
End time     : 2025-04-23T17:22:26
Elapsed time : 00:02:49 (Timelimit=01:00:00)

Job ID: 7327074
Cluster: i5
User/Group: cjm1n19/fp
State: FAILED (exit code 1)
Nodes: 1
Cores per node: 32
CPU Utilized: 00:24:27
CPU Efficiency: 27.13% of 01:30:08 core-walltime
Job Wall-clock time: 00:02:49
Memory Utilized: 16.59 GB
Memory Efficiency: 0.00% of 16.00 B

